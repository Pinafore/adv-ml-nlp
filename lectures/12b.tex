\documentclass[compress]{beamer}
\usefonttheme{professionalfonts}

\input{course_style}


\usepackage{amsmath}
\usepackage{bm}

\newcommand{\graphscale}{.6}

\newcommand{\gfx}[2]{
\begin{center}
	\includegraphics[width=#2\linewidth]{topic_models/#1}
\end{center}
}
\title{Topic Models}
\date{Evaluation}

\begin{document}


\frame{\titlepage
}


\frame{
\frametitle{Evaluation}
\begin{center}
\only<1>{\includegraphics[width=\linewidth]{eval/heldout_2} }
\only<2>{\includegraphics[width=\linewidth]{eval/heldout_4}  \\
	\large Measures predictive power, not what the topics are}
\end{center}

\begin{center}
\includegraphics[width=0.5\linewidth]{topic_models/equations/evaluation} \\
How you compute it is important too
\end{center}

}

\frame{
  \frametitle{Word Intrusion}

  \includegraphics[width=\linewidth]{eval/nyt_topics_wide}
}


\frame{
  \frametitle{Word Intrusion}

  \begin{enumerate}
    \item Take the highest probability words from a topic

      \begin{block}{Original Topic}
        dog, cat, horse, pig, cow
      \end{block}
\pause
    \item Take a high-probability word from another topic and add it
      \begin{block}{Topic with Intruder}
        dog, cat, \alert<2->{apple}, horse, pig, cow
      \end{block}
\pause
     \item We ask users to find the word that doesn't belong
  \end{enumerate}
\begin{block}{Hypothesis}
If the topics are interpretable, users will consistently choose true intruder
\end{block}
}

\frame{
\frametitle{Word Intrusion}
\begin{center}
\only<1>{\includegraphics[width=\linewidth]{eval/word1}  }
\only<2>{\includegraphics[width=\linewidth]{eval/word2}  }
\pause
  \begin{itemize}
    \item Order of words was shuffled
    \item Which intruder was selected varied
    \item Model precision: percentage of users who clicked on intruder
  \end{itemize}

\end{center}
}

\frame{
\frametitle{Word Intrusion: Which Topics are Interpretable?}
  \begin{block}{New York Times, 50 LDA Topics}
    \begin{center}
      \includegraphics[width=0.8\linewidth]{eval/topic_precision}
    \end{center}
  \end{block}
  \begin{center}
    Model Precision: percentage of correct intruders found
  \end{center}
}



\frame{

\frametitle{Interpretability and Likelihood}
\begin{center}
\only<1>{Model Precision on New York Times}
\only<2>{Topic Log Odds on Wikipedia}
\end{center}

\begin{columns}
\column{.85\linewidth}
\begin{flushright}
  \only<1>{\includegraphics[scale=\graphscale]{eval/mp}}
  \only<2>{\includegraphics[scale=\graphscale]{eval/tlo}}
  \only<1>{\includegraphics[scale=\graphscale]{eval/mp_y}\includegraphics[scale=\graphscale]{eval/nyt_mp}}
  \only<2>{\includegraphics[scale=\graphscale]{eval/tlo_y}\includegraphics[scale=\graphscale]{eval/wiki_tlo}} \\
  \only<1>{\includegraphics[scale=\graphscale]{eval/nyt_x}}
  \only<2>{\includegraphics[scale=\graphscale]{eval/wiki_x}}
\end{flushright}
\column{.15\linewidth}
  \includegraphics[scale=\graphscale]{eval/legend}
\end{columns}
\vspace{-0.75cm}
\begin{center}
  \includegraphics[scale=\graphscale]{eval/held-out} \\
\only<1> {within a model, higher likelihood $\not =$ higher interpretability}
\only<2> {across models, higher likelihood $\not =$ higher interpretability}
\end{center}
}

\begin{frame}{Downstream Tasks}

\begin{itemize}
  \item \alert<2>{Classification}
  \item Machine Translation
  \item Political Polarization/Framing
\end{itemize}


\end{frame}




\end{document}
