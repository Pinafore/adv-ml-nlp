\documentclass[compress]{beamer}
\usefonttheme{professionalfonts}

\input{course_style}


\usepackage{amsmath}
\usepackage{bm}

\newcommand{\graphscale}{.6}

\newcommand{\gfx}[2]{
\begin{center}
	\includegraphics[width=#2\linewidth]{topic_models/#1}
\end{center}
}
\title{Topic Models}
\date{Evaluation}

\begin{document}


\frame{\titlepage
}


\frame{
\frametitle{Evaluation}
\begin{center}
\only<1>{\includegraphics[width=\linewidth]{eval/heldout_2} }
\only<2>{\includegraphics[width=\linewidth]{eval/heldout_4}  \\
	\large Measures predictive power, not what the topics are}
\end{center}

\begin{center}
\includegraphics[width=0.5\linewidth]{topic_models/equations/evaluation} \\
How you compute it is important too
\end{center}

}

\frame{
  \frametitle{Word Intrusion}

  \includegraphics[width=\linewidth]{eval/nyt_topics_wide}
}


\frame{
  \frametitle{Word Intrusion}

  \begin{enumerate}
    \item Take the highest probability words from a topic

      \begin{block}{Original Topic}
        dog, cat, horse, pig, cow
      \end{block}
\pause
    \item Take a high-probability word from another topic and add it
      \begin{block}{Topic with Intruder}
        dog, cat, \alert<2->{apple}, horse, pig, cow
      \end{block}
\pause
     \item We ask users to find the word that doesn't belong
  \end{enumerate}
\begin{block}{Hypothesis}
If the topics are interpretable, users will consistently choose true intruder
\end{block}
}

\frame{
\frametitle{Word Intrusion}
\begin{center}
\only<1>{\includegraphics[width=\linewidth]{eval/word1}  }
\only<2>{\includegraphics[width=\linewidth]{eval/word2}  }
\pause
  \begin{itemize}
    \item Order of words was shuffled
    \item Which intruder was selected varied
    \item Model precision: percentage of users who clicked on intruder
  \end{itemize}

\end{center}
}

\frame{
\frametitle{Word Intrusion: Which Topics are Interpretable?}
  \begin{block}{New York Times, 50 LDA Topics}
    \begin{center}
      \includegraphics[width=0.8\linewidth]{eval/topic_precision}
    \end{center}
  \end{block}
  \begin{center}
    Model Precision: percentage of correct intruders found
  \end{center}
}



\frame{

\frametitle{Interpretability and Likelihood}
\begin{center}
\only<1>{Model Precision on New York Times}
\only<2>{Topic Log Odds on Wikipedia}
\end{center}

\begin{columns}
\column{.85\linewidth}
\begin{flushright}
  \only<1>{\includegraphics[scale=\graphscale]{eval/mp}}
  \only<2>{\includegraphics[scale=\graphscale]{eval/tlo}}
  \only<1>{\includegraphics[scale=\graphscale]{eval/mp_y}\includegraphics[scale=\graphscale]{eval/nyt_mp}}
  \only<2>{\includegraphics[scale=\graphscale]{eval/tlo_y}\includegraphics[scale=\graphscale]{eval/wiki_tlo}} \\
  \only<1>{\includegraphics[scale=\graphscale]{eval/nyt_x}}
  \only<2>{\includegraphics[scale=\graphscale]{eval/wiki_x}}
\end{flushright}
\column{.15\linewidth}
  \includegraphics[scale=\graphscale]{eval/legend}
\end{columns}
\vspace{-0.75cm}
\begin{center}
  \includegraphics[scale=\graphscale]{eval/held-out} \\
\only<1> {within a model, higher likelihood $\not =$ higher interpretability}
\only<2> {across models, higher likelihood $\not =$ higher interpretability}
\end{center}
}

\begin{frame}{Downstream Tasks}

\begin{itemize}
  \item \alert<2>{Classification}
  \item Machine Translation
  \item Political Polarization/Framing
\end{itemize}


\end{frame}


\begin{frame}{Evaluation}

  \begin{itemize}
    \item User study
    \item 40 minutes
    \item Sort documents into categories
    \item What information / interface \alert<2>{helps best}
      \pause
      \pause
      \begin{itemize}
        \item Train a classifier on human examples
          \only<4->{\alert<4>{(don't tell them how many labels)}}
        \item Compare classifier labels to expert judgements
          \only<5->{\alert<5>{(purity)}}
\only<5>{
\begin{equation}
\mbox{purity}(\mathbf{U},\mathbf{G}) = \frac{1}{N}\sum\limits_{l} \max\limits_{j}|U_l \cap G_j|,
\end{equation}
}
      \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}{Which is more Useful?}

\only<1>{
  \begin{center}
    Who should drive?
  \end{center}
}


\only<2->{
\begin{columns}
  \column{.5\linewidth}
    \begin{block}{Active Learning}
      \begin{center}
        \includegraphics[width=.85\linewidth]{eval/active_learning}
      \end{center}
    \end{block}
  \column{.5\linewidth}
  \pause
    \begin{block}{Topic Models}
      \begin{center}
        \includegraphics[width=.475\linewidth]{eval/nyt_topics}
      \end{center}

    \end{block}


\end{columns}
}

\end{frame}

\fsi{eval/alto_interface}{}
\fsi{eval/alto_interface_highlight}{Direct users
  to document}



\fsi{eval/user_talk_1}{ Active learning if time is short}
\fsi{eval/user_talk_2}{ Better than status quo}
\fsi{eval/user_talk_3}{ Active learning can
  help topic models }
\fsi{eval/user_talk_4}{ Topic models help
  users understand the collection }
\fsi{eval/user_talk_4}{ Moral: machines and
  humans together (if you let them) }



\begin{frame}
  \frametitle{Evaluation Takeaway}

  \begin{itemize}
    \item Measure what you care about
      \item If you care about prediction, likelihood is good
\item If you care about a particular task, measure that
    \end{itemize}

\end{frame}


\end{document}
